{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provides the functionality for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import argparse\n",
    "from argparse import RawTextHelpFormatter\n",
    "import emoji\n",
    "import sys\n",
    "from termcolor import colored, cprint\n",
    "import tensorflow as tf\n",
    "from dataloader import preprocess, load_data, build_tokenizer\n",
    "from model import transformer\n",
    "from train import main\n",
    "\n",
    "__author__ = \"ilias Zavitsanos\"\n",
    "__version__ = \"1.0\"\n",
    "__maintainer__ = \"ilias Zavitsanos\"\n",
    "__email__ = \"izavits@gmail.com\"\n",
    "__status__ = \"Research Ready\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"Load the model from disk, the weights and the needed parameters\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('../config.ini')\n",
    "    model_name = config['DATA']['InputSet'].split('/')[-1].split('.')[0]\n",
    "    with open('../models/' + model_name + '_config.json') as json_file:\n",
    "        json_config = json_file.read()\n",
    "    # Hyper-parameters\n",
    "    NUM_LAYERS = int(config['MODEL']['NumLayers'])\n",
    "    D_MODEL = int(config['MODEL']['Dmodel'])\n",
    "    NUM_HEADS = int(config['MODEL']['NumHeads'])\n",
    "    UNITS = int(config['MODEL']['Units'])\n",
    "    DROPOUT = float(config['MODEL']['Dropout'])\n",
    "    model = transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        units=UNITS,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout=DROPOUT)\n",
    "    model.load_weights('../models/' + model_name + '_model.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to evaluate input and provide prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_params():\n",
    "    \"\"\"Get dataset needed parameters:\n",
    "    the tokenizer, start and end tokens and vocabulary size\n",
    "    \"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('../config.ini')\n",
    "    datafile = '../' + config['DATA']['InputSet']\n",
    "    inputs, outputs = load_data(datafile)\n",
    "    data_tokenizer, START_TOKEN, END_TOKEN, VOCAB_SIZE = build_tokenizer(inputs, outputs)\n",
    "    return START_TOKEN, END_TOKEN, data_tokenizer, VOCAB_SIZE\n",
    "\n",
    "\n",
    "def evaluate(utterance):\n",
    "    \"\"\"Evaluate the given utterance and return output.\n",
    "    Apply the same preprocessing method used to prepare the data\n",
    "    for training.\"\"\"\n",
    "    utterance = preprocess(utterance)\n",
    "    utterance = tf.expand_dims(START_TOKEN + data_tokenizer.encode(utterance) + END_TOKEN, axis=0)\n",
    "    output = tf.expand_dims(START_TOKEN, 0)\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[utterance, output], training=False)\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "        # concatenate the predicted word to the decoder input\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "    return tf.squeeze(output, axis=0)\n",
    "\n",
    "\n",
    "def predict(utterance):\n",
    "    \"\"\"Evaluate the given utterance and return the predicted sentence.\"\"\"\n",
    "    prediction = evaluate(utterance)\n",
    "    predicted_sentence = data_tokenizer.decode(\n",
    "        [i for i in prediction if i < data_tokenizer.vocab_size])\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get necessary parameters, load the model and start the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get necessary parameters\n",
    "START_TOKEN, END_TOKEN, data_tokenizer, VOCAB_SIZE = get_data_params()\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "MAX_LENGTH = int(config['MODEL']['MaxLength'])\n",
    "# Parse command line arguments\n",
    "welcome = \"Welcome to chatbot.\\n\"\n",
    "welcome += \"Use the config.ini file to setup the required parameters and input dataset.\\n\"\n",
    "welcome += \"Start chatting with the bot. Type 'bye' or Ctrl^C to exit\"\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "# Start prompt and make predictions\n",
    "print('\\n\\n')\n",
    "print(colored('Summoning chatbot..', 'red', attrs=['bold']))\n",
    "print('\\n\\n')\n",
    "print(colored(emoji.emojize(':robot_face: :speech_balloon: >> Hello how can I help you?'),\n",
    "                 'green'))\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input('User >> ')\n",
    "        if user_input == 'bye':\n",
    "            print(colored(emoji.emojize(':robot_face: :speech_balloon: >> bye bye then'),\n",
    "                              'green'))\n",
    "                print('')\n",
    "            sys.exit(1)\n",
    "        output = predict(user_input)\n",
    "        print(colored(emoji.emojize(':robot_face: :speech_balloon: >> ' + output), 'green'))\n",
    "    except KeyboardInterrupt:\n",
    "        print('')\n",
    "        print(colored(emoji.emojize(':robot_face: :speech_balloon: >> bye bye then'),\n",
    "                          'green'))\n",
    "        print('')\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
